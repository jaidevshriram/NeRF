{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f1198c2",
   "metadata": {},
   "source": [
    "# Things to Do\n",
    "\n",
    "1. Build a ray sampler - the montecarlo and NDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce0cd72e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _C: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkornia\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m psnr\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# from pytorch3d.structures import Volumes\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# from pytorch3d.transforms import so3_exp_map\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch3d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrenderer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#     FoVPerspectiveCameras, \u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#     NDCMultinomialRaysampler,\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     MonteCarloRaysampler,\n\u001b[0;32m     16\u001b[0m     EmissionAbsorptionRaymarcher,\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#     ImplicitRenderer,\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#     RayBundle,\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#     ray_bundle_to_ray_points,\u001b[39;00m\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# from model.transformers import PositionalEncoding\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\3d\\lib\\site-packages\\pytorch3d\\renderer\\__init__.py:7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# All rights reserved.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the BSD-style license found in the\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblending\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     BlendParams,\n\u001b[0;32m      9\u001b[0m     hard_rgb_blend,\n\u001b[0;32m     10\u001b[0m     sigmoid_alpha_blend,\n\u001b[0;32m     11\u001b[0m     softmax_rgb_blend,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcamera_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m join_cameras_as_batch, rotate_on_spot\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcameras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# deprecated  # deprecated  # deprecated  # deprecated\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     camera_position_from_spherical_angles,\n\u001b[0;32m     16\u001b[0m     CamerasBase,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m     SfMPerspectiveCameras,\n\u001b[0;32m     28\u001b[0m )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\3d\\lib\\site-packages\\pytorch3d\\renderer\\blending.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NamedTuple, Sequence, Union\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch3d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _C\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch3d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatatypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Device\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Example functions for blending the top K colors per pixel using the outputs\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# from rasterization.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# NOTE: All blending function should return an RGBA image per batch element\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _C: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from kornia.metrics import psnr\n",
    "\n",
    "# from pytorch3d.structures import Volumes\n",
    "# from pytorch3d.transforms import so3_exp_map\n",
    "from pytorch3d.renderer import (\n",
    "#     FoVPerspectiveCameras, \n",
    "#     NDCMultinomialRaysampler,\n",
    "    MonteCarloRaysampler,\n",
    "    EmissionAbsorptionRaymarcher,\n",
    "#     ImplicitRenderer,\n",
    "#     RayBundle,\n",
    "#     ray_bundle_to_ray_points,\n",
    ")\n",
    "\n",
    "# from model.transformers import PositionalEncoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1426de08",
   "metadata": {},
   "source": [
    "# Ray Sampler Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e14a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.common.compat import meshgrid_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "44e3e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonteCarloRaysampler(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "        min_dim: float,\n",
    "        max_dim: float,\n",
    "        n_rays_per_image: int,\n",
    "        n_pts_per_ray: int,\n",
    "        min_depth: float,\n",
    "        max_depth: float\n",
    "    ) -> None:\n",
    "        \n",
    "        self.min_dim = min_dim\n",
    "        self.max_dim = max_dim\n",
    "        self.n_rays_per_image = n_rays_per_image\n",
    "        self.n_pts_per_ray = n_pts_per_ray\n",
    "        self.min_depth = min_depth\n",
    "        self.max_depth = max_depth\n",
    "        pass\n",
    "        \n",
    "    def test(self, cameras):\n",
    "        \n",
    "        i, j = self.min_dim + torch.rand((cameras.shape[0], self.n_rays_per_image, 2)) * (self.max_dim - self.min_dim)\n",
    "        print(i.T)\n",
    "        print(i.t())\n",
    "        \n",
    "        return i, j\n",
    "        \n",
    "#         xrange = torch.arange(min_x, max_x, )\n",
    "#         self.img_grid_xy = torch.meshgrid(xrange, yrange, indexing=\"ij\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "339411ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "raysampler = MonteCarloRaysampler(\n",
    "                min_dim=0,\n",
    "                max_dim=1,\n",
    "                n_rays_per_image=750,\n",
    "                n_pts_per_ray=128,\n",
    "                min_depth=0,\n",
    "                max_depth=6\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5dabacd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9645, 0.9112, 0.7975,  ..., 0.0616, 0.2851, 0.5872],\n",
      "        [0.7636, 0.7744, 0.5587,  ..., 0.4142, 0.1410, 0.0342]])\n",
      "tensor([[0.9645, 0.9112, 0.7975,  ..., 0.0616, 0.2851, 0.5872],\n",
      "        [0.7636, 0.7744, 0.5587,  ..., 0.4142, 0.1410, 0.0342]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9645, 0.7636],\n",
       "         [0.9112, 0.7744],\n",
       "         [0.7975, 0.5587],\n",
       "         ...,\n",
       "         [0.0616, 0.4142],\n",
       "         [0.2851, 0.1410],\n",
       "         [0.5872, 0.0342]]),\n",
       " tensor([[0.0113, 0.0272],\n",
       "         [0.2613, 0.3563],\n",
       "         [0.2630, 0.7345],\n",
       "         ...,\n",
       "         [0.0309, 0.9141],\n",
       "         [0.6883, 0.7569],\n",
       "         [0.7867, 0.9581]]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raysampler.test(torch.Tensor([1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4a6509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
